{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv(\"./index.csv\")\n",
    "demographics = pd.read_csv(\"./demographics.csv\")\n",
    "epidemiology = pd.read_csv(\"./epidemiology.csv\")\n",
    "geography = pd.read_csv(\"./geography.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "  def __init__(self, index, demographics, epidemiology):\n",
    "    super().__init__()\n",
    "    self.locations = set(index[\"location_key\"].dropna())\n",
    "    self.base_locations = [\"TW\", \"US\", \"BR\"]\n",
    "    self.used_indices = []\n",
    "    self.populations = []\n",
    "    self.split = 0.7\n",
    "    self.range = 14\n",
    "    data = {}\n",
    "    labels = {}\n",
    "    populations = {}\n",
    "    for loc, group in demographics.groupby(\"location_key\"):\n",
    "      data[loc] = group[group.columns[1:]].to_numpy()\n",
    "    for loc, group in epidemiology.groupby(\"location_key\"):\n",
    "      if loc not in data: continue\n",
    "      population = data[loc][0][0]\n",
    "      if population == 0: continue\n",
    "      history = (group[group.columns[2:]] / population).to_numpy()\n",
    "      data[loc] = np.concatenate((data[loc].repeat(len(history), 0), history), 1) / population\n",
    "      labels[loc] = (group[group.columns[2:]][\"new_confirmed\"]).to_numpy() / population\n",
    "      data[loc] = np.nan_to_num(data[loc])\n",
    "      labels[loc] = np.nan_to_num(labels[loc])\n",
    "      populations[loc] = population\n",
    "    for loc in [loc for loc in self.locations if len([0 for ul in self.base_locations if ul in loc])]:\n",
    "      if loc in data and loc in labels and int(len(data[loc]) * (1 - self.split)) > self.range: self.used_indices.append(loc)\n",
    "    self.samples = [torch.tensor(data[loc], dtype=torch.float) for loc in self.used_indices]\n",
    "    self.labels = [torch.tensor(labels[loc], dtype=torch.float) for loc in self.used_indices]\n",
    "    self.populations = [populations[loc] for loc in self.used_indices]\n",
    "\n",
    "  def __getitem__(self, loc):\n",
    "    r = random.randint(self.range, int(len(self.samples[loc]) * self.split))\n",
    "    return self.samples[loc][r - self.range:r], self.labels[loc][r - 1]\n",
    "\n",
    "  def get_validation(self):\n",
    "    loc = random.randint(0, len(self.used_indices) - 1)\n",
    "    r = random.randint(int(len(self.samples[loc]) * self.split) + self.range, len(self.samples[loc]))\n",
    "    return self.samples[loc][r - self.range:r].unsqueeze(0), self.labels[loc][r - 1].unsqueeze(0), self.populations[loc]\n",
    "\n",
    "  def __len__(self): return len(self.used_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "NUM_STEPS = 1000\n",
    "NUM_VALID = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of used locations: 9064\n"
     ]
    }
   ],
   "source": [
    "dataset = COVID19Dataset(index, demographics, epidemiology)\n",
    "torch.save(dataset, \"./data/dataset.pt\")\n",
    "print(f\"number of used locations: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0], dtype=int64),)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(dataset.labels != 0))\n",
    "print(dataset.labels[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"./data/dataset.pt\")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self, r, p = 7):\n",
    "    super().__init__()\n",
    "    self.r = r # range of tracking\n",
    "    self.p = p # period of sampling\n",
    "    self.seq1 = nn.Sequential(\n",
    "      nn.Conv1d(26, 64, self.p),\n",
    "      nn.ReLU(True),\n",
    "    )\n",
    "    self.lstm = nn.LSTM(8, 256, 2, batch_first=True, bidirectional=True)\n",
    "    self.seq2 = nn.Sequential(\n",
    "      nn.ReLU(),\n",
    "      nn.Flatten(),\n",
    "      nn.Dropout(0.3),\n",
    "      nn.Linear(64 * 256 * 2, 1024),\n",
    "      nn.ReLU(True),\n",
    "      nn.Linear(1024, 256),\n",
    "      nn.ReLU(True),\n",
    "      nn.Linear(256, 1),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    outputs = self.seq1(inputs.permute(0, 2, 1))\n",
    "    outputs, _ = self.lstm(outputs)\n",
    "    outputs = self.seq2(outputs)\n",
    "    return outputs.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 14, 26])\n",
      "torch.Size([4])\n",
      "tensor([0.0000e+00, 0.0000e+00, 3.0487e-05, 0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(dataloader))[0].shape)\n",
    "print(next(iter(dataloader))[1].shape)\n",
    "print(next(iter(dataloader))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.9234e-05, 8.6159e-06, 4.1294e-04, 2.0968e-04])\n",
      "tensor([0.5065, 0.5068, 0.5062, 0.5062], grad_fn=<SqueezeBackward1>)\n",
      "0.2562870681285858\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "model = Model(dataset.range)\n",
    "samples, labels = next(iter(dataloader))\n",
    "outputs = model(samples)\n",
    "loss = loss_fn(outputs, labels)\n",
    "print(labels)\n",
    "print(outputs)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/1000:\t0.2204\n",
      "200/1000:\t0.0004\n",
      "300/1000:\t0.0004\n",
      "400/1000:\t0.0004\n",
      "500/1000:\t0.0003\n",
      "600/1000:\t0.0006\n",
      "700/1000:\t0.0003\n",
      "800/1000:\t0.0003\n",
      "900/1000:\t0.0003\n",
      "1000/1000:\t0.0003\n",
      "Training Ended!\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Model(dataset.range)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5, weight_decay=1e-5)\n",
    "loss_fn = nn.MSELoss()\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "if device == \"cuda\": model.cuda()\n",
    "for step in range(1, NUM_STEPS + 1):\n",
    "  optimizer.zero_grad()\n",
    "  samples, labels = next(iter(dataloader))\n",
    "  outputs = model(samples.to(device))\n",
    "  loss = torch.sqrt(loss_fn(outputs.to(device), labels.to(device)))\n",
    "  losses.append(loss.item())\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  if step % 100 == 0:\n",
    "    print(f\"{step}/{NUM_STEPS}:\\t{np.mean(losses):.4f}\")\n",
    "    losses = []\n",
    "print(\"Training Ended!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population: 8693\n",
      "predict: 0.0001\n",
      "reality: 0.0012\n",
      "error rate: -0.0011\n",
      "error: -9\n",
      "population: 51659\n",
      "predict: 0.0001\n",
      "reality: 0.0032\n",
      "error rate: -0.0031\n",
      "error: -159\n",
      "population: 35509\n",
      "predict: 0.0001\n",
      "reality: 0.0036\n",
      "error rate: -0.0035\n",
      "error: -125\n",
      "population: 41354\n",
      "predict: 0.0001\n",
      "reality: 0.0022\n",
      "error rate: -0.0021\n",
      "error: -85\n",
      "population: 9881\n",
      "predict: 0.0005\n",
      "reality: 0.0033\n",
      "error rate: -0.0028\n",
      "error: -27\n",
      "population: 2514\n",
      "predict: 0.0001\n",
      "reality: 0.0119\n",
      "error rate: -0.0118\n",
      "error: -29\n",
      "population: 2077\n",
      "predict: 0.0001\n",
      "reality: 0.0140\n",
      "error rate: -0.0139\n",
      "error: -28\n",
      "population: 17723\n",
      "predict: 0.0001\n",
      "reality: 0.0038\n",
      "error rate: -0.0037\n",
      "error: -66\n",
      "population: 5751\n",
      "predict: 0.0001\n",
      "reality: 0.0023\n",
      "error rate: -0.0021\n",
      "error: -12\n",
      "population: 22373\n",
      "predict: 0.0001\n",
      "reality: 0.0032\n",
      "error rate: -0.0031\n",
      "error: -68\n",
      "population: 6961\n",
      "predict: 0.0001\n",
      "reality: 0.0011\n",
      "error rate: -0.0011\n",
      "error: -7\n",
      "population: 14595\n",
      "predict: 0.0001\n",
      "reality: 0.0018\n",
      "error rate: -0.0018\n",
      "error: -25\n",
      "population: 3950\n",
      "predict: 0.0001\n",
      "reality: 0.0030\n",
      "error rate: -0.0029\n",
      "error: -11\n",
      "unacceptable cases: 13\n",
      "mean error rate: -0.0005\n"
     ]
    }
   ],
   "source": [
    "unacceptable = 0\n",
    "error_rate_sum = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for step in range(1, NUM_VALID + 1):\n",
    "    samples, labels, population = dataset.get_validation()\n",
    "    outputs = model(samples.to(device))\n",
    "    error_rate = (outputs - labels.to(device)).item()\n",
    "    error = int(error_rate * population)\n",
    "    if abs(error_rate) < 1e-3 and abs(error) < 1000: continue\n",
    "    print(f\"population: {int(population)}\")\n",
    "    print(f\"predict: {outputs.item():.4f}\")\n",
    "    print(f\"reality: {labels.item():.4f}\")\n",
    "    print(f\"error rate: {error_rate:.4f}\")\n",
    "    print(f\"error: {error}\")\n",
    "    unacceptable += 1\n",
    "    error_rate_sum += error_rate\n",
    "\n",
    "print(f\"unacceptable cases: {unacceptable}\")\n",
    "print(f\"mean error rate: {error_rate_sum / NUM_VALID:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
